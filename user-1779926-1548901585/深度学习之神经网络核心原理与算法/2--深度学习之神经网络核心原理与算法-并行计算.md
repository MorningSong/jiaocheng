上一章我们介绍了基本的前馈神经网络的实现。

本节我们来介绍一些可以提高神经网络学习效率的方法。

## 并行计算

加快神经网络训练最直接的方式。我们需要得到的是一个网络的拓扑结构和各个节点上权重值的矩阵。


以一个小规模的全连接网络为例:

![mark](http://myphoto.mtianyan.cn/blog/180331/Bc08HleJmh.png?imageslim)

>假设有5层，每层10个节点，输入向量有1000维。最后一层是一个节点，那么这个网络中一共有多少个权值需要被训练出来。

- 第一层: 1000维 乘以 10个节点
- 第二层，三层，四层。 10 乘以 10
- 第五层: 10 乘以 1个

加起来: 10000+300+10 =10310个维度

学习率: 0.001 假设挪动: 2000次 总共需要挪动20620000次

正常的情况下这个挪动是串行的，下一次挪动必须等待上一次挪动完毕。挪动等待时间，求导。

我们测试练习用cpu是可以的。但是工业是不够的

![mark](http://myphoto.mtianyan.cn/blog/180331/bff17cbCCE.png?imageslim)

>成熟方案: 使用NVIDIA显卡 装上cuda 使用gpu进行并行计算。一块显卡拥有很多的cuda内核可以进行并行计算。

### cuda

![mark](http://myphoto.mtianyan.cn/blog/180331/bj5a860mmj.png?imageslim)

不同型号的显卡，cuda核心数也不同。型号越新cuda数越多。

训练的数据不是放在电脑的内存中，而是会被拷贝至gpu的显存中。显存越大，训练数据支持越大。

cuda支持复杂的并行计算，如果我们使用了TensorFlow之类的框架，就不需要关心底层的并行计算的cuda实现。我们不需要和cuda打交道。

一个工作站安装多块显卡。国内的一些合作企业。

